import urllib.request
import urllib.error
import time
import hashlib
import shutil
from pathlib import Path
import json
import re


class ProjectMirrorSync:
    """é¡¹ç›®é•œåƒåŒæ­¥å™¨ - æ¸…ç†HTMLæ³¨å…¥è„šæœ¬"""

    def __init__(self, base_url, local_path, check_interval=60):
        self.base_url = base_url.rstrip('/')
        self.local_path = Path(local_path)
        self.check_interval = check_interval
        self.hash_file = self.local_path / '.file_hashes.json'
        self.file_hashes = self.load_hashes()
        self.stats = {'downloaded': 0, 'skipped': 0, 'failed': 0}

    def load_hashes(self):
        if self.hash_file.exists():
            try:
                with open(self.hash_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return {}
        return {}

    def save_hashes(self):
        try:
            self.local_path.mkdir(parents=True, exist_ok=True)
            with open(self.hash_file, 'w', encoding='utf-8') as f:
                json.dump(self.file_hashes, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"  ä¿å­˜å“ˆå¸Œå¤±è´¥: {e}")

    def get_file_hash(self, content):
        if isinstance(content, str):
            content = content.encode('utf-8')
        return hashlib.md5(content).hexdigest()

    def get_local_file_hash(self, file_path):
        try:
            if not file_path.exists():
                return None
            with open(file_path, 'rb') as f:
                return self.get_file_hash(f.read())
        except:
            return None

    def download_file(self, url):
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Cache-Control': 'no-cache',
                'Pragma': 'no-cache',
            }
            req = urllib.request.Request(url, headers=headers)
            with urllib.request.urlopen(req, timeout=30) as response:
                return response.read()
        except urllib.error.HTTPError as e:
            print(f"    HTTPé”™è¯¯ {e.code}")
            return None
        except Exception as e:
            print(f"    ä¸‹è½½å¤±è´¥: {str(e)[:50]}")
            return None

    def clean_html(self, content):
        """
        æ¸…ç†HTMLä¸­æ³¨å…¥çš„è„šæœ¬
        åªä¿ç•™ <!DOCTYPE> åˆ° </html> ä¹‹é—´çš„åŸå§‹å†…å®¹
        """
        try:
            text = content.decode('utf-8', errors='ignore')

            # æ–¹æ³•1: æ‰¾åˆ°</html>æ ‡ç­¾ï¼Œæˆªæ–­åé¢çš„å†…å®¹
            html_end = text.find('</html>')
            if html_end != -1:
                # æ‰¾åˆ°</html>æ ‡ç­¾çš„ç»“æŸä½ç½®
                html_end_tag = html_end + len('</html>')
                text = text[:html_end_tag]

            # æ–¹æ³•2: ç§»é™¤</body>å’Œ</html>ä¹‹é—´çš„æ³¨å…¥è„šæœ¬
            # è¿™äº›è„šæœ¬é€šå¸¸åœ¨</body>åé¢ï¼Œ</html>å‰é¢
            text = re.sub(
                r'(</body>\s*)<script>.*?livereload.*?</script>\s*(<script>.*?</script>\s*)*\s*(</html>)',
                r'\1\3',
                text,
                flags=re.DOTALL | re.IGNORECASE
            )

            # æ–¹æ³•3: ç›´æ¥ç§»é™¤LiveReloadç›¸å…³çš„scriptæ ‡ç­¾
            patterns = [
                r'<script>document\.write\(.*?livereload\.js.*?\)</script>',
                r'<script>\s*document\.addEventListener\(.*?LiveReloadDisconnect.*?\)</script>',
                r'<script>\s*class\s+reloadPlugin.*?</script>',
                r'<script[^>]*src=["\'][^"\']*livereload\.js[^"\']*["\'][^>]*></script>',
                r'<script[^>]*src=["\'][^"\']*:35929[^"\']*["\'][^>]*></script>',
            ]

            for pattern in patterns:
                text = re.sub(pattern, '', text, flags=re.DOTALL | re.IGNORECASE)

            # æ¸…ç†</html>åé¢çš„æ‰€æœ‰å†…å®¹
            text = re.sub(r'(</html>).*$', r'\1', text, flags=re.DOTALL)

            # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
            text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)

            # ç¡®ä¿ä»¥</html>ç»“å°¾
            text = text.strip()
            if not text.endswith('</html>'):
                text += '\n</html>'

            return text.encode('utf-8')

        except Exception as e:
            print(f"    æ¸…ç†HTMLå¤±è´¥: {e}")
            return content

    def compare_and_download(self, remote_path):
        """å¯¹æ¯”å¹¶ä¸‹è½½æ–‡ä»¶"""
        url = f"{self.base_url}/{remote_path}"
        file_icon = self.get_file_icon(remote_path)
        local_file = self.local_path / remote_path

        # ä¸‹è½½è¿œç¨‹æ–‡ä»¶
        remote_content = self.download_file(url)
        if not remote_content:
            print(f"  âŒ {file_icon} {remote_path}")
            self.stats['failed'] += 1
            return False

        # æ£€æŸ¥æ˜¯å¦æ˜¯404é¡µé¢
        text = remote_content.decode('utf-8', errors='ignore')
        if '404' in text and 'Page Not Found' in text:
            print(f"  âŒ {file_icon} {remote_path} (404)")
            self.stats['failed'] += 1
            return False

        # å¦‚æœæ˜¯HTMLæ–‡ä»¶ï¼Œæ¸…ç†æ³¨å…¥çš„è„šæœ¬
        if remote_path.endswith(('.html', '.htm')):
            remote_content = self.clean_html(remote_content)

        # è®¡ç®—å“ˆå¸Œ
        remote_hash = self.get_file_hash(remote_content)
        local_hash = self.get_local_file_hash(local_file)
        stored_hash = self.file_hashes.get(remote_path)

        # å¯¹æ¯”
        if local_hash == remote_hash and stored_hash == remote_hash:
            print(f"  â­ï¸  {file_icon} {remote_path} (æœªå˜åŒ–)")
            self.stats['skipped'] += 1
            return True

        # ä¿å­˜
        try:
            local_file.parent.mkdir(parents=True, exist_ok=True)
            with open(local_file, 'wb') as f:
                f.write(remote_content)

            self.file_hashes[remote_path] = remote_hash

            if local_hash is None:
                print(f"  âœ¨ {file_icon} {remote_path} (æ–°æ–‡ä»¶)")
            else:
                print(f"  ğŸ”„ {file_icon} {remote_path} (å·²æ›´æ–°)")

            self.stats['downloaded'] += 1
            return True

        except Exception as e:
            print(f"  âŒ {file_icon} {remote_path} - {e}")
            self.stats['failed'] += 1
            return False

    def get_file_icon(self, filename):
        if filename.endswith(('.html', '.htm')):
            return "ğŸ“„"
        elif filename.endswith('.css'):
            return "ğŸ¨"
        elif filename.endswith('.js'):
            return "âš™ï¸"
        elif filename.endswith(('.jpg', '.jpeg', '.png', '.gif', '.svg', '.ico', '.webp')):
            return "ğŸ–¼ï¸"
        elif filename.endswith(('.woff', '.woff2', '.ttf', '.eot', '.otf')):
            return "ğŸ”¤"
        else:
            return "ğŸ“¦"

    def get_file_structure(self):
        """
        âš ï¸ è¯·åœ¨è¿™é‡Œæ·»åŠ æ‚¨çš„é¡¹ç›®æ–‡ä»¶åˆ—è¡¨
        """
        return [
            'index.html',
            # æ·»åŠ æ›´å¤šæ–‡ä»¶...
            # 'css/style.css',
            # 'js/main.js',
            # 'images/logo.png',
        ]

    def scan_local_files(self):
        files = []
        if not self.local_path.exists():
            return files

        for item in self.local_path.rglob('*'):
            if item.is_file() and item.name != '.file_hashes.json':
                rel_path = item.relative_to(self.local_path)
                files.append(str(rel_path).replace('\\', '/'))

        return files

    def sync_project(self, auto_detect=False):
        print(f"\n{'=' * 70}")
        print(f"ğŸ”„ å¼€å§‹åŒæ­¥é¡¹ç›®")
        print(f"{'=' * 70}\n")

        self.stats = {'downloaded': 0, 'skipped': 0, 'failed': 0}

        if auto_detect and self.local_path.exists():
            print("ğŸ” è‡ªåŠ¨æ£€æµ‹æœ¬åœ°æ–‡ä»¶...")
            file_list = self.scan_local_files()
            if file_list:
                print(f"   å‘ç° {len(file_list)} ä¸ªæ–‡ä»¶")
            else:
                file_list = self.get_file_structure()
        else:
            file_list = self.get_file_structure()

        if not file_list:
            print("âŒ æ–‡ä»¶åˆ—è¡¨ä¸ºç©ºï¼")
            print("ğŸ’¡ è¯·åœ¨ get_file_structure() ä¸­æ·»åŠ æ–‡ä»¶")
            return

        print(f"ğŸ“‹ æ–‡ä»¶æ€»æ•°: {len(file_list)}\n")

        for i, file_path in enumerate(file_list, 1):
            print(f"[{i:3d}/{len(file_list)}] ", end='')
            self.compare_and_download(file_path)

        self.save_hashes()

        print(f"\n{'=' * 70}")
        print(f"âœ… åŒæ­¥å®Œæˆ")
        print(f"{'=' * 70}")
        print(f"  âœ¨ æ–°å¢/æ›´æ–°: {self.stats['downloaded']} ä¸ª")
        print(f"  â­ï¸  æœªå˜åŒ–: {self.stats['skipped']} ä¸ª")
        if self.stats['failed'] > 0:
            print(f"  âŒ å¤±è´¥: {self.stats['failed']} ä¸ª")
        print(f"{'=' * 70}\n")

    def test_connection(self):
        print(f"\nğŸ” æµ‹è¯•è¿æ¥...")
        test_url = f"{self.base_url}/index.html"
        print(f"   URL: {test_url}")

        content = self.download_file(test_url)
        if not content:
            print(f"   âŒ æ— æ³•è®¿é—®")
            return False

        text = content.decode('utf-8', errors='ignore')
        if '404' in text and 'Page Not Found' in text:
            print(f"   âŒ è¿”å›404")
            return False

        # æ˜¾ç¤ºæ¸…ç†å‰åå¯¹æ¯”
        print(f"   âœ… è¿æ¥æˆåŠŸ")
        print(f"   åŸå§‹å¤§å°: {len(content)} å­—èŠ‚")

        cleaned = self.clean_html(content)
        print(f"   æ¸…ç†å: {len(cleaned)} å­—èŠ‚")
        print(f"   ç§»é™¤äº†: {len(content) - len(cleaned)} å­—èŠ‚çš„æ³¨å…¥å†…å®¹")

        return True

    def check_updates(self):
        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
        print(f"\n{'=' * 70}")
        print(f"â° [{timestamp}] æ£€æŸ¥æ›´æ–°")
        print(f"{'=' * 70}")

        index_url = f"{self.base_url}/index.html"
        remote_content = self.download_file(index_url)

        if not remote_content:
            print("âŒ æ— æ³•è®¿é—®")
            return False

        text = remote_content.decode('utf-8', errors='ignore')
        if '404' in text and 'Page Not Found' in text:
            print("âŒ è¿”å›404")
            print(f"ğŸ’¡ URL: {index_url}")
            return False

        # æ¸…ç†åè®¡ç®—å“ˆå¸Œ
        cleaned_content = self.clean_html(remote_content)
        remote_hash = self.get_file_hash(cleaned_content)

        local_file = self.local_path / 'index.html'
        local_hash = self.get_local_file_hash(local_file)

        if local_hash != remote_hash:
            print(f"âœ¨ æ£€æµ‹åˆ°å˜åŒ–ï¼")
            if local_hash:
                print(f"   æœ¬åœ°: {local_hash[:16]}...")
                print(f"   è¿œç¨‹: {remote_hash[:16]}...")
            else:
                print(f"   é¦–æ¬¡åŒæ­¥")

            self.backup()
            auto_detect = local_hash is not None
            self.sync_project(auto_detect=auto_detect)
            return True
        else:
            print("âœ“ æ— å˜åŒ–")
            return False

    def backup(self):
        if not self.local_path.exists():
            return

        has_content = any(item.name != '.file_hashes.json'
                          for item in self.local_path.iterdir())
        if not has_content:
            return

        try:
            backup_name = f"{self.local_path.name}_backup_{time.strftime('%Y%m%d_%H%M%S')}"
            backup_path = self.local_path.parent / backup_name
            print(f"\nğŸ’¾ å¤‡ä»½: {backup_name}")
            shutil.copytree(self.local_path, backup_path,
                            ignore=shutil.ignore_patterns('.file_hashes.json'))
        except Exception as e:
            print(f"   å¤‡ä»½å¤±è´¥: {e}")

    def start(self):
        print("=" * 70)
        print("ğŸš€ é¡¹ç›®é•œåƒåŒæ­¥å™¨ (HTMLå‡€åŒ–ç‰ˆ)")
        print("=" * 70)
        print(f"ğŸ“¡ è¿œç¨‹: {self.base_url}")
        print(f"ğŸ’¾ æœ¬åœ°: {self.local_path}")
        print(f"â±ï¸  é—´éš”: {self.check_interval}ç§’")
        print(f"ğŸ§¹ è‡ªåŠ¨æ¸…ç†LiveReloadç­‰æ³¨å…¥è„šæœ¬")
        print(f"âŒ¨ï¸  Ctrl+C åœæ­¢")
        print("=" * 70)

        if not self.test_connection():
            print("\nâŒ è¿æ¥å¤±è´¥")
            return

        print("\nğŸ” é¦–æ¬¡åŒæ­¥...")
        self.check_updates()

        print(f"\nğŸ‘€ å¼€å§‹ç›‘æ§...\n")

        while True:
            try:
                time.sleep(self.check_interval)
                self.check_updates()
            except KeyboardInterrupt:
                print("\n\n" + "=" * 70)
                print("ğŸ‘‹ å·²åœæ­¢")
                print("=" * 70)
                break
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {e}")
                print("â³ ç»§ç»­ç›‘æ§...\n")


def main():
    # ==================== é…ç½® ====================
    REMOTE_URL = "http://172.16.229.130:8848/7-2(1)"
    LOCAL_PATH = r"C:\Users\Administrator\Documents\HBuilderProjects\7-2(1)-1"
    CHECK_INTERVAL = 60
    # =============================================

    print("\n" + "=" * 70)
    print("ğŸ“‹ é…ç½®")
    print("=" * 70)
    print(f"è¿œç¨‹: {REMOTE_URL}")
    print(f"æœ¬åœ°: {LOCAL_PATH}")
    print(f"é—´éš”: {CHECK_INTERVAL}ç§’")
    print("=" * 70)

    try:
        confirm = input("\nå¼€å§‹åŒæ­¥ï¼Ÿ(å›è½¦ç»§ç»­ / nå–æ¶ˆ): ").strip().lower()
        if confirm == 'n':
            return
    except:
        pass

    syncer = ProjectMirrorSync(REMOTE_URL, LOCAL_PATH, CHECK_INTERVAL)
    syncer.start()


if __name__ == "__main__":
    main()